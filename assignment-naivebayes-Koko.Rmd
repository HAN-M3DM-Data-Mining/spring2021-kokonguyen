---
title: "Assigment - Naive Bayes DIY"
author:
  - Koko Nguyen - Author
  - Vy Nguyen - Reviewer
date: "`r format(Sys.time(), '%d %B, %Y')`"
output:
   html_notebook:
    toc: true
    toc_depth: 2
---

```{r}
library(tidyverse)
library(tm)
library(caret)
library(wordcloud)
library(e1071)
```
---


## Business Understanding

The chosen dataset for this NB classification is Fake News

## Data Understanding
```{r}
url <- "https://raw.githubusercontent.com/HAN-M3DM-Data-Mining/assignments/master/datasets/NB-fakenews.csv"
rawDF <- read_csv(url)
head(rawDF)
```

The data set has 5 variables (columns) and 20800 observations (rows)

After reading the data set, we find out that variable ID, author and text do not contain any relevant information for our prediction. Hence, we will remove column 1,3 and 4 which represent these data.

```{r}
cleanDF <- rawDF[c(-1,-3,-4)] %>% na.omit
head(cleanDF)
```


The variable label is numeric value with 0: reliable and 1: unreliable. As it indicates whether the tittle belongs to the category "Reliable" or "Unreliable", we will convert it into a factor variable.
```{r}
cleanDF$label <- factor(cleanDF$label, levels = c("0", "1"), labels = c("Reliable", "Unreliable")) %>% relevel("Reliable")
class(cleanDF$label)
```

For visually inspect, we create a wordcloud for two variables. 

```{r}
Unreliable <- cleanDF %>% filter(label == "Unreliable")
Reliable <- cleanDF %>% filter(label == "Reliable")

wordcloud(Unreliable$title, max.words = 20, scale = c(4, 0.8), colors= c("indianred1","indianred2","indianred3","indianred"))
wordcloud(Reliable$title, max.words = 20, scale = c(4, 0.8), colors= c("lightsteelblue1","lightsteelblue2","lightsteelblue3","lightsteelblue"))
```
There is no significant difference between the number of reliable vs unreliable articles released. Based on the wordclouds, it is likely that the name of former US president his rival in the 2016 election would take place in many unreliable titles. While in the reliable side, "new","york" and "times" also appeared to be mentioned multiple times.


## Data Preparation

We create a corpus aims to refer to a collection of text document
```{r}
rawCorpus <- Corpus(VectorSource(cleanDF$title))
inspect(rawCorpus[1:3])
```
The corpus contains 20242 elements which matches with the number of rows in our dataset.
We will also change everything to lowercase and remove numbers as these will contain litle information on whether an article is reliable or not

```{r}
cleanCorpus <- rawCorpus %>% tm_map(tolower) %>% tm_map(removeNumbers)
inspect(cleanCorpus[1:3])
```
We also remove stopwords, punctuation and whitespaces

```{r}
cleanCorpus <- cleanCorpus %>% tm_map(tolower) %>% tm_map(removeWords, stopwords()) %>% tm_map(removePunctuation)
inspect(cleanCorpus[1:3])
```
Remove additional whitespace

```{r}
cleanCorpus <- cleanCorpus %>% tm_map(stripWhitespace)
inspect(cleanCorpus[1:3])
```
Compare with the raw version

```{r}
tibble(Raw = rawCorpus$content[1:3], Clean = cleanCorpus$content[1:3])
```

After cleaning up the text, we transform the messages to a matrix 

```{r}
cleanDTM <- cleanCorpus %>% DocumentTermMatrix
inspect(cleanDTM)
```
Dataset will be splitted into train and test sets

```{r}
# Create split indices
set.seed(1234)
trainIndex <- createDataPartition(cleanDF$label, p = .75, 
                                  list = FALSE, 
                                  times = 1)
head(trainIndex)
```



```{r}
# Apply split indices to DF
trainDF <- cleanDF[trainIndex, ]
testDF <- cleanDF[-trainIndex, ]

```
```{r}
# Apply split indices to Corpus
trainCorpus <- cleanCorpus[trainIndex]
testCorpus <- cleanCorpus[-trainIndex]
```

```{r}
# Apply split indices to DTM
trainDTM <- cleanDTM[trainIndex, ]
testDTM <- cleanDTM[-trainIndex, ]
```

Eliminate words with low frequencies

```{r}
freqWords <- trainDTM %>% findFreqTerms(10)
trainDTM <-  DocumentTermMatrix(trainCorpus, list(dictionary = freqWords))
testDTM <-  DocumentTermMatrix(testCorpus, list(dictionary = freqWords))
```

We will now transform the numerical matrix of words count into a factor that indicates whether the words appear in the document or not

```{r}
convert_counts <- function(x) {
  x <- ifelse(x > 0, 1, 0) %>% factor(levels = c(0,1), labels = c("No", "Yes"))
}

nColsDTM <- dim(trainDTM)[2]
trainDTM <- apply(trainDTM, MARGIN = 2, convert_counts)
testDTM <- apply(testDTM, MARGIN = 2, convert_counts)

head(trainDTM[,1:10])
```


## Modeling

```{r}
nbayesModel <-  naiveBayes(trainDTM, trainDF$label, laplace = 1)
```

```{r}
predVec <- predict(nbayesModel, testDTM)
confusionMatrix(predVec, testDF$label, positive = "Unreliable", dnn = c("Prediction", "True"))
```

## Evaluation and Deployment
The model has an accuracy rate of 92,3% which is quite a good result.  

## Reviews

The code ran well through the script.
The command "head()" should be in different chunk to avoid the delay in processing the code.
The Business Understand should be more solid and more context to understand more about background information.
